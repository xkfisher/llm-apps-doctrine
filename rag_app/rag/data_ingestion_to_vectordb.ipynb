{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0091589-d964-40c6-a4b7-09ecf597197e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ingest massive amounts of data to a Vector DB (Amazon OpenSearch)\n",
    "**_Use of Amazon OpenSearch as a vector database for storing embeddings_**\n",
    "\n",
    "This notebook works well with the `conda_python3` kernel on a SageMaker Notebook `ml.t3.xlarge` instance.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background-(Problem-Description-and-Approach))\n",
    "1. [Overall Workflow](#Overall-Workflow)\n",
    "1. [Create scripts for ingesting data into OpenSearch](#Create-scripts-for-ingesting-data-into-OpenSearch)\n",
    "1. [Download the data from the web and upload to S3](#Download-the-data-from-the-web-and-upload-to-S3)\n",
    "1. [Load the data in a OpenSearch index (Local mode)](#Load-the-data-in-a-OpenSearch-index-(Local-mode))\n",
    "1. [Load the data in a OpenSearch index via SageMaker Processing Job (Distributed mode)](#Load-the-data-in-a-OpenSearch-index-via-SageMaker-Processing-Job-(Distributed-mode))\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c0dd9-bcb5-409f-8a4a-adab5ef47e42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook illustrates how to use [`langchain`](https://python.langchain.com/en/latest/index.html) Amazon Sagemaker Endpoints and Amazon Sagemaker Processing Job to convert large amount of data into embeddings and ingest the text data along with its embeddings into an Amazon OpenSearch index.\n",
    "\n",
    "We use the documents from [sagemaker.readthedocs.io/en/stable](sagemaker.readthedocs.io/en/stable) as the dataset to convert into embeddings. The [`gpt-j-6b`](https://huggingface.co/EleutherAI/gpt-j-6b) large language model (LLM) is to generate the embeddings. \n",
    "\n",
    "To understand the code, you might also find it useful to refer to:\n",
    "\n",
    "- *[The langchain OpenSearch documentation](https://python.langchain.com/en/latest/ecosystem/opensearch.html)*\n",
    "- *[Amazon OpenSearch service documentation](https://docs.aws.amazon.com/opensearch-service/index.html)*\n",
    "- *[SageMaker Processing Job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html)*\n",
    "---\n",
    "\n",
    "## Background (Problem Description and Approach)\n",
    "\n",
    "- **Problem statement**: \n",
    "\n",
    "Using LLMs for information retrieval tasks (such as question-answering) requires converting the knowledge corpus as well as user questions into vector embeddings. We want to generate these vector embeddings using an LLM hosted as a Amazon Sagemaker Endpoint and store it in a vector database of choice such as Amazon OpenSearch. For converting large amounts of data (TBs or PBs) we need a scalable system which can accomplish both converting the documents into embeddings, storing them in a vector database and provide low latency similarity search\n",
    "\n",
    "- **Our approach**: \n",
    "\n",
    "1. Host the LLM use to generate the embeddings as a SageMaker Endpoint with `instance_count` set to > 1 (the exact number depends upon time taken to generate the embeddings for the amount of data we have and the dollar amount we want to spend on it; more instances would mean greater cost but also lesser time taken).\n",
    "\n",
    "1. Place the data to be corpus of data in S3 (each document is a file stored as an object in S3).\n",
    "\n",
    "1. Use a Python script that uses [langchain](https://python.langchain.com/en/latest/index.html) and [Opensearch-py](https://pypi.org/project/opensearch-py/) to ingest the data into OpenSearch. Run the script locally on this notebook for testing.\n",
    "\n",
    "1. Create a Sagemaker Processing job with `instance_count` set to > 1 (usually matching the `instance_count` for the Sagemaker Endpoint). \n",
    "\n",
    "    Each instance of the SageMaker Processing Job runs a script that does the following:\n",
    "    - Processes a subset of files from S3.\n",
    "    - Uses langchain to read the files from the local filesystem and convert it into chunks.\n",
    "    - Creates a langchain `OpenSearchVectorSearch` object and provides it a `SagemakerJumpstartEmbeddings` object that enables it to talk to our Sagemaker Endpoint.\n",
    "    - Uses the langchain `OpenSearchVectorSearch` to create or get an existing Opensearch index and then ingests documents into the index which contain the original `text`, `embeddings` and `metadata`.\n",
    "    - Does this using Pytohn multiprocessing to achieve parallelization even within a single processing job instance and ensure maximum use of the Sagemaker Endpoint instance's GPU.\n",
    "    > **The advantage to using langchain as a wrapper for interfacing with a vector database is that it provides a generic pattern that can be used with any LLM and any vector store. Langchain automatically uses the OpenSearch bulk ingestion API endpoint for ingesting data rather than ingesting data one record at a time. Furthermore, langchain also provides an opinionated JSON structure that includes text and metadata alongwith the embeddings itself for storing embeddings in an OpenSearch index specifically for information retrieval use-cases**.\n",
    "\n",
    "- **Our tools**: [Amazon SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/), [langchain](https://python.langchain.com/en/latest/index.html) and [Opensearch-py](https://pypi.org/project/opensearch-py/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a32334-88aa-431a-a306-f9fc3030f6cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Workflow\n",
    "\n",
    "**Prerequisite**\n",
    "\n",
    "The following are prerequisites that needs to be accomplised by running [this cloud formation template](./template.yaml) before running this notebook.\n",
    "- A Sagemaker Endpoint for generating embeddings.\n",
    "- An Amazon OpenSearch cluster for storing embeddings.\n",
    "    - Opensearch cluster's access credentials (username and password) stored in AWS Secrets Mananger by following steps described [here](https://docs.aws.amazon.com/secretsmanager/latest/userguide/managing-secrets.html).\n",
    "\n",
    "The overall workflow for this notebook is as follows:\n",
    "1. Install the required Python packages and store session information in local variables.\n",
    "1. Download data from source and upload to S3.\n",
    "1. Run the Python script locally to ingest a subset of data into an OpenSearch index for testing.\n",
    "1. Run Sagemaker Processing Job which reads all data from S3 and runs the same Python script as above to ingest data into OpenSearch.\n",
    "    - As part of this step we also create a custom container to package langchain and opensearch Python packages.\n",
    "1. Do a similarity search with embeddings stored in the OpenSearch index for an input query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acd36d-a1c9-41b0-b412-7af957b2580f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24ca243-fb69-4422-97ba-5a41c38a4b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.132 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-3.15.1-py3-none-any.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.0/271.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-3.15.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install ipywidgets==7.0.0 langchain==0.0.149 opensearch-py==2.2.0 faiss_cpu==1.7.4 --quiet\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822a0889-6149-4216-9633-ff66d201181c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sagemaker.processing import ScriptProcessor, FrameworkProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4647260-5368-4793-b1dc-2853b453218c",
   "metadata": {},
   "source": [
    "Change the parameters if you would like to scrape a different website for data, customize chunk size etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d2fa335-c7a2-46ec-a14b-3e898f899975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "# WEBSITE=\"https://sagemaker.readthedocs.io/en/stable/\"\n",
    "DOMAIN=\"doctrine\"\n",
    "DATA_DIR = \"docs\"\n",
    "MAX_OS_DOCS_PER_PUT = 1000\n",
    "IMAGE = \"load-data-opensearch-custom\"\n",
    "IMAGE_TAG = \"latest\"\n",
    "CHUNK_SIZE_FOR_DOC_SPLIT = 1000\n",
    "CHUNK_OVERLAP_FOR_DOC_SPLIT = 500\n",
    "CREATE_OS_INDEX_HINT_FILE = \"_create_index_hint\"\n",
    "FAISS_INDEX_DIR = \"faiss_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42612999-1cf9-46c7-a978-95f5991f1ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s,%(module)s,%(processName)s,%(levelname)s,%(message)s', level=logging.INFO, stream=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0453eb-9781-4ac7-b320-271620f7d18f",
   "metadata": {},
   "source": [
    "### Read parameters from Cloud Formation stack\n",
    "\n",
    "Some of the resources needed for this notebook such as the Embeddings LLM model endpoint, the Amazon OpenSearch cluster are created outside of this notebook, typically through a cloud formation template. We now read the outputs and parameters of the cloud formation stack created from that template to get the value of these parameters. \n",
    "\n",
    "The stack name here should match the stack name you used when creating the cloud formation stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3c3dc1e-65a1-482f-9027-46eaea80742f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if used a different name while creating the cloud formation stack then change this to match the name you used\n",
    "CFN_STACK_NAME = \"llm-apps-blog-rag2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814ff8c-b8f9-43fb-bb2b-da690a95bf68",
   "metadata": {
    "tags": []
   },
   "source": [
    "**If you did not use a cloud formation template for creating these resources then set the names of these resources manually in the code below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde8bcc6-d0ed-4813-9595-8d7c2e720027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#boto3.client('cloudformation').describe_stacks(StackName=\"ssome\")\n",
    "stacks = boto3.client('cloudformation').list_stacks()\n",
    "stack_found = CFN_STACK_NAME in [stack['StackName'] for stack in stacks['StackSummaries']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4849d39-c2ca-4e21-a505-61b6a4970615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 08:46:03,018,2617774421,MainProcess,INFO,cfn outputs={'EmbeddingEndpointName': 'llm-apps-blog-gpt-j-6b-endpoint-152d6870', 'OpenSourceDomainArn': 'arn:aws:es:us-east-1:613526579489:domain/opensearchservi-hsbfpnvhbwad', 'OpenSearchDomainEndpoint': 'search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com', 'LLMEndpointName': 'llm-apps-blog-flan-t5-xxl-endpoint-152d6870', 'SageMakerNotebookURL': 'https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances/openNotebook/aws-llm-apps-blog1?view=classic', 'Region': 'us-east-1', 'OpenSearchDomainName': 'opensearchservi-hsbfpnvhbwad', 'LLMAppAPIEndpoint': 'https://jqiv4luk6h.execute-api.us-east-1.amazonaws.com/prod/', 'OpenSearchSecret': 'arn:aws:secretsmanager:us-east-1:613526579489:secret:OpenSearchSecret-llm-apps-blog-rag2-20kDRX'}\n",
      "params={'SageMakerIAMRole': 'LLMAppsBlogIAMRole', 'SageMakerNotebookName': 'aws-llm-apps-blog1', 'OpenSearchIndexName': 'llm_apps_workshop_embeddings', 'LambdaFunctionName': 'LLMApp1', 'OpenSearchUsername': 'opensearchuser', 'APIGatewayName': 'LLMAppAPIGW', 'ApiStageName': 'prod', 'OpenSearchPassword': '****', 'AppName': 'llm-apps-blog'}\n"
     ]
    }
   ],
   "source": [
    "def get_cfn_outputs(stackname: str) -> List:\n",
    "    cfn = boto3.client('cloudformation')\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "def get_cfn_parameters(stackname: str) -> List:\n",
    "    cfn = boto3.client('cloudformation')\n",
    "    params = {}\n",
    "    for param in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Parameters']:\n",
    "        params[param['ParameterKey']] = param['ParameterValue']\n",
    "    return params\n",
    "\n",
    "if stack_found is True:\n",
    "    outputs = get_cfn_outputs(CFN_STACK_NAME)\n",
    "    params = get_cfn_parameters(CFN_STACK_NAME)\n",
    "    logger.info(f\"cfn outputs={outputs}\\nparams={params}\")\n",
    "\n",
    "    embeddings_model_endpoint_name = outputs['EmbeddingEndpointName']\n",
    "    opensearch_domain_endpoint = f\"https://{outputs['OpenSearchDomainEndpoint']}\"\n",
    "    opensearch_index = params['OpenSearchIndexName']\n",
    "    app_name = params['AppName']\n",
    "    # ARN of the secret is of the following format arn:aws:secretsmanager:region:account_id:secret:my_path/my_secret_name-autoid\n",
    "    os_creds_secretid_in_secrets_manager = \"-\".join(outputs['OpenSearchSecret'].split(\":\")[-1].split('-')[:-1])\n",
    "else:\n",
    "    logger.info(f\"cloud formation stack {CFN_STACK_NAME} not found, set parameters manually here\")\n",
    "    # REPLACE THE \"placeholder\" WITH ACTUAL VALUES IF YOU CREATED THESE RESOURCES WITHOUT USING A CLOUD FORMATION TEMPLATE\n",
    "    embeddings_model_endpoint_name = \"placeholder\"\n",
    "    opensearch_domain_endpoint = \"placeholder\"\n",
    "    opensearch_index = \"placeholder\"\n",
    "    os_creds_secretid_in_secrets_manager = \"placeholder\"\n",
    "    app_name = \"llm-apps-blogs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d37de-df4c-409e-b4ca-d05b8cbca56b",
   "metadata": {},
   "source": [
    "The embeddings model endpoint name, OpenSearch domain endpoint and the identifier for the OpenSearch credentials stored in the Secrets Mananger are all available as `Outputs` from the cloud formation stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54fbde3d-cc6c-49ef-bf82-ecaf69034c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 08:46:03,023,796691109,MainProcess,INFO,embeddings_model_endpoint_name=llm-apps-blog-gpt-j-6b-endpoint-152d6870,\n",
      "opensearch_domain_endpoint=https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com,\n",
      "os_creds_secretid_in_secrets_manager=OpenSearchSecret-llm-apps-blog-rag2,opensearch_index=llm_apps_workshop_embeddings\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"embeddings_model_endpoint_name={embeddings_model_endpoint_name},\\nopensearch_domain_endpoint={opensearch_domain_endpoint},\\n\"\n",
    "            f\"os_creds_secretid_in_secrets_manager={os_creds_secretid_in_secrets_manager},opensearch_index={opensearch_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25fc00c6-d5e3-4776-93a3-5d5ed6a3e729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 08:46:11,607,1323976668,MainProcess,INFO,aws_role=arn:aws:iam::613526579489:role/service-role/AmazonSageMaker-ExecutionRole-20221102T161968, aws_region=us-east-1, bucket=sagemaker-us-east-1-613526579489\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "logger.info(f\"aws_role={aws_role}, aws_region={aws_region}, bucket={bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c446f0-b282-420f-9fbb-bdd9d28d87b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb2f4b53-23fe-4efd-9d5a-9211d7c2fe79",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Upload files into the S3 bucket listed above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95833d54-d6bb-4d4c-97b6-9157cd9bcabf",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Step 3: Load data into `OpenSearch`\n",
    "\n",
    "We are now ready to create scripts which will read data from the local directory, use langchain to create embeddings and then upload the embeddings into OpenSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a0545c-b593-4319-b355-4dacee393416",
   "metadata": {},
   "source": [
    "### Read credentials from AWS Secrets Manager\n",
    "\n",
    "The credentials for the OpenSearch cluster are store in AWS Secrets Mananger, our code reads the credentials from there and provides them to the opensearch-py package (through langchain API)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de107289-6b61-445e-ad53-310db4f08946",
   "metadata": {},
   "source": [
    "### SageMaker embeddings for langchain\n",
    "\n",
    "langchain provides the [`SagemakerEndpointEmbeddings`]() class which is a wrapper around a functionality to talk to a Sagemaker Endpoint to generate embeddings. We will override the `embed_documents` function to define our own batching strategy for sending requests to the model (multiple requests are sent in one model invocation). Similarly, we extend the `ContentHandlerBase` class to provide implementation for two abstract methods which define how to process (encode/decode) the input data sent to the model and the output received from the model.\n",
    "\n",
    "We finally create a `SagemakerEndpointEmbeddingsJumpStart` object that puts all this together and can now be used by langchain to talk to an LLM deployed as a Sagemaker Endpoint to generate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31e78c-f65c-4662-8bb6-f98ed880d307",
   "metadata": {},
   "source": [
    "### Script to load data into OpenSearch\n",
    "\n",
    "This script puts everything together, it divides the documents into chunks, then uses the langchain package to create embeddings (through `SagemakerEndpointEmbeddingsJumpStart`) and then ingests the data into OpenSearch using `OpenSearchVectorSearch`. \n",
    "\n",
    "The langchain `OpenSearchVectorSearch` provides a wrapper over the `opensearch-py` package. It uses the `/_bulk` API endpoint for ingesting multiple records in a single PUT request.\n",
    "\n",
    "Default chunk size: 1000 tokens.\n",
    "\n",
    "Default overlap size: 500 tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdc58d-b6b2-42c5-8c45-bd73623051ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Load the data in a [FAISS](https://github.com/facebookresearch/faiss) index (Local mode)\n",
    "\n",
    "We now create a FAISS index to store the embeddings. This is an alternative to OpenSearch for storing embeddings in-memory. We write the FAISS index locally and then upoad the files to an S3 bucket. A Lambda function can then download these files from S3 and load the FAISS index in memory to perform a similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2171e-b3f6-4c5b-b4ba-4b46eeca282c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.9/site-packages (0.13.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (4.9.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pypdf in /opt/conda/lib/python3.9/site-packages (3.14.0)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /opt/conda/lib/python3.9/site-packages (from pypdf) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install xmltodict\n",
    "!pip install lxml\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd390b-ad1c-439b-bd25-9777f9391f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fd41570-e61c-4c75-9c27-7cfd3c827ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 18:41:11,053,<ipython-input-33-ee4f77e961b5>,MainProcess,INFO,Loading documents ...\n",
      "2023-08-14 18:41:39,178,<ipython-input-33-ee4f77e961b5>,MainProcess,INFO,Time taken: 28.124929904937744 seconds. 2474 chunks generated\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from container.sm_helper import create_sagemaker_embeddings_from_js_model\n",
    "embeddings = create_sagemaker_embeddings_from_js_model(embeddings_model_endpoint_name, aws_region)\n",
    "\n",
    "# loader = ReadTheDocsLoader(\"docs\",features=\"html.parser\")\n",
    "loader = PyPDFLoader(\"docs/14 OPFOR Tactics.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=CHUNK_SIZE_FOR_DOC_SPLIT,\n",
    "    chunk_overlap=CHUNK_OVERLAP_FOR_DOC_SPLIT,\n",
    "    # length_function=len,\n",
    ")\n",
    "    \n",
    "# read all the docs, split them into chunks. \n",
    "st = time.time() \n",
    "logger.info('Loading documents ...')\n",
    "docs = loader.load()\n",
    "\n",
    "# add a custom metadata field, such as timestamp\n",
    "for doc in docs:\n",
    "    doc.metadata['timestamp'] = time.time()\n",
    "    doc.metadata['embeddings_model'] = embeddings_model_endpoint_name\n",
    "chunks = text_splitter.create_documents([doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs])\n",
    "et = time.time() - st\n",
    "logger.info(f'Time taken: {et} seconds. {len(chunks)} chunks generated') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2d20a-7f68-45ca-830d-169ae2090ad2",
   "metadata": {},
   "source": [
    "Load the chunks into FAISS, we provide the embeddings object so that langchain can first convert the text chunks into embeddings and then store those embeddings into a FAISS index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "52670206-9631-4c1c-aea6-f8a0d93421d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:55:41,761,sm_helper,MainProcess,INFO,got results for 2474 in 461.32011461257935s, length of embeddings list is 2474\n"
     ]
    }
   ],
   "source": [
    "#temp embedding endpoint\n",
    "embeddings = create_sagemaker_embeddings_from_js_model(\"jumpstart-dft-hf-textembedding-gpt-j-6b\", aws_region)\n",
    "\n",
    "vector_db = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcd3e9-0a2c-4e6b-963f-aacb2a4106bf",
   "metadata": {},
   "source": [
    "Save to a local directory and upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3971a475-0ce2-4443-b66a-8c70f5b72d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db_path = FAISS_INDEX_DIR\n",
    "vector_db.save_local(vector_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f2b05bc-d8b5-42ee-84c0-0c744e84e092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: faiss_index/index.pkl to s3://sagemaker-us-east-1-613526579489/llm-apps-blog/faiss_index/index.pkl\n",
      "upload: faiss_index/index.faiss to s3://sagemaker-us-east-1-613526579489/llm-apps-blog/faiss_index/index.faiss\n"
     ]
    }
   ],
   "source": [
    "# upload this data to S3, to be used when we run the Sagemaker Processing Job\n",
    "!aws s3 cp --recursive $vector_db_path/ s3://$bucket/$app_name/$vector_db_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016a278-9e64-43bd-867f-1adb87136bd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load the data in a `OpenSearch` index via SageMaker Processing Job (Distributed mode)\n",
    "\n",
    "We now have a working script that is able to ingest data into an OpenSearch index. But for this to work for massive amounts of data we need to scale up the processing by running this code in a distributed fashion. We will do this using Sagemkaer Processing Job. This involves the following steps:\n",
    "\n",
    "1. Create a custom container in which we will install the `langchain` and `opensearch-py` packges and then upload this container image to Amazon Elastic Container Registry (ECR).\n",
    "2. Use the Sagemaker `ScriptProcessor` class to create a Sagemaker Processing job that will run on multiple nodes.\n",
    "    - The data files available in S3 are automatically distributed across in the Sagemaker Processing Job instances by setting `s3_data_distribution_type='ShardedByS3Key'` as part of the `ProcessingInput` provided to the processing job.\n",
    "    - Each node processes a subset of the files and this brings down the overall time required to ingest the data into Opensearch.\n",
    "    - Each node also uses Python `multiprocessing` to internally also parallelize the file processing. Thus, **there are two levels of parallelization happening, one at the cluster level where individual nodes are distributing the work (files) amongst themselves and another at the node level where the files in a node are also split between multiple processes running on the node**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cced6-5e83-46d3-9c6e-cb0602f1ddf3",
   "metadata": {},
   "source": [
    "### Create custom container\n",
    "\n",
    "We will now create a container locally and push the container image to ECR. **The container creation process takes about 1 minute**.\n",
    "\n",
    "1. The container include all the Python packages we need i.e. `langchain`, `opensearch-py`, `sagemaker` and `beautifulsoup4`.\n",
    "1. The container also includes the `credentials.py` script for retrieving credentials from Secrets Manager and `sm_helper.py` for helping to create SageMaker endpoint classes that langchain uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c76456-f381-44b2-ae35-70563e9cb4cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 08:46:50,495,2352485635,MainProcess,INFO,region=us-east-1, account_id=613526579489\n"
     ]
    }
   ],
   "source": [
    "# Run script to build docker custom containe image and push it to ECR \n",
    "# Set region and sagemaker URI variables \n",
    "session = boto3.session.Session()\n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "logger.info(f\"region={aws_region}, account_id={account_id}\")\n",
    "# !bash scripts/build_and_push.sh $(pwd)/container $IMAGE $IMAGE_TAG $aws_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0022cd-0934-45ef-8741-5a9ebd7cd6fe",
   "metadata": {},
   "source": [
    "### Create and run the Sagemaker Processing Job\n",
    "\n",
    "Now we will run the Sagemaker Processing Job to ingest the data into OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76b96fcd-0f05-4c14-b838-808214f2a187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_model_endpoint_name = 'jumpstart-dft-hf-textembedding-gpt-j-6b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3465b51-b6a3-47de-83b9-de5c95b5dfe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in /opt/conda/lib/python3.10/site-packages (1.16.3)\n",
      "Requirement already satisfied: pdfminer in /opt/conda/lib/python3.10/site-packages (20191125)\n",
      "Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (3.15.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from pdf2image) (9.4.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from pdfminer) (3.18.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pdf2image pdfminer pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a372961d-cf5e-4066-a3d4-64c16f900b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "621bb019-8b4c-4ff0-8f1f-0b7deaaf5c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 11:42:54,910,2568289917,MainProcess,INFO,base_job_name=llm-apps-blog-job, tags=[{'Key': 'data', 'Value': 'embeddings-for-llm-apps'}], image_uri=613526579489.dkr.ecr.us-east-1.amazonaws.com/load-data-opensearch-custom:latest, instance_type=ml.m5.xlarge, instance_count=3\n",
      "2023-08-15 11:42:54,933,2568289917,MainProcess,INFO,creating an opensearch index with name=llm_apps_workshop_embeddings\n",
      "2023-08-15 11:42:55,137,session,MainProcess,INFO,Creating processing-job with name llm-apps-blog-job-2023-08-15-11-42-54-933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................\u001b[34m2023-08-15 11:46:48,109,load_data_into_opensearch,MainProcess,INFO,Received arguments Namespace(opensearch_cluster_domain='https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com', opensearch_secretid='OpenSearchSecret-llm-apps-blog-rag2', opensearch_index_name='llm_apps_workshop_embeddings', aws_region='us-east-1', embeddings_model_endpoint_name='jumpstart-dft-hf-textembedding-gpt-j-6b', chunk_size_for_doc_split=1000, chunk_overlap_for_doc_split=500, input_data_dir='/opt/ml/processing/input_data', process_count=2, create_index_hint_file='_create_index_hint')\u001b[0m\n",
      "\u001b[34m2023-08-15 11:46:48,110,load_data_into_opensearch,MainProcess,INFO,there are 9 files to process in the /opt/ml/processing/input_data folder\u001b[0m\n",
      "\u001b[34m2023-08-15 11:46:48,262,load_data_into_opensearch,MainProcess,INFO,processing ms_2525d.pdf\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/load_data_into_opensearch.py\", line 93, in <module>\n",
      "    loader = PyPDFLoader(fn)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 92, in __init__\n",
      "    super().__init__(file_path)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 56, in __init__\n",
      "    raise ValueError(\"File path %s is not a valid file or url\" % self.file_path)\u001b[0m\n",
      "\u001b[34mValueError: File path ms_2525d.pdf is not a valid file or url\u001b[0m\n",
      "\n",
      "\u001b[32m2023-08-15 11:46:48,153,load_data_into_opensearch,MainProcess,INFO,Received arguments Namespace(opensearch_cluster_domain='https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com', opensearch_secretid='OpenSearchSecret-llm-apps-blog-rag2', opensearch_index_name='llm_apps_workshop_embeddings', aws_region='us-east-1', embeddings_model_endpoint_name='jumpstart-dft-hf-textembedding-gpt-j-6b', chunk_size_for_doc_split=1000, chunk_overlap_for_doc_split=500, input_data_dir='/opt/ml/processing/input_data', process_count=2, create_index_hint_file='_create_index_hint')\u001b[0m\n",
      "\u001b[32m2023-08-15 11:46:48,153,load_data_into_opensearch,MainProcess,INFO,there are 9 files to process in the /opt/ml/processing/input_data folder\u001b[0m\n",
      "\u001b[32m2023-08-15 11:46:48,297,load_data_into_opensearch,MainProcess,INFO,processing FM_3-90.pdf\u001b[0m\n",
      "\u001b[32mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/load_data_into_opensearch.py\", line 93, in <module>\n",
      "    loader = PyPDFLoader(fn)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 92, in __init__\n",
      "    super().__init__(file_path)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 56, in __init__\n",
      "    raise ValueError(\"File path %s is not a valid file or url\" % self.file_path)\u001b[0m\n",
      "\u001b[32mValueError: File path FM_3-90.pdf is not a valid file or url\u001b[0m\n",
      "\u001b[34m2023-08-15 11:46:48,113,load_data_into_opensearch,MainProcess,INFO,Received arguments Namespace(opensearch_cluster_domain='https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com', opensearch_secretid='OpenSearchSecret-llm-apps-blog-rag2', opensearch_index_name='llm_apps_workshop_embeddings', aws_region='us-east-1', embeddings_model_endpoint_name='jumpstart-dft-hf-textembedding-gpt-j-6b', chunk_size_for_doc_split=1000, chunk_overlap_for_doc_split=500, input_data_dir='/opt/ml/processing/input_data', process_count=2, create_index_hint_file='_create_index_hint')\u001b[0m\n",
      "\u001b[34m2023-08-15 11:46:48,113,load_data_into_opensearch,MainProcess,INFO,there are 10 files to process in the /opt/ml/processing/input_data folder\u001b[0m\n",
      "\u001b[34m2023-08-15 11:46:48,252,load_data_into_opensearch,MainProcess,INFO,processing FM_7-0.pdf\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/load_data_into_opensearch.py\", line 93, in <module>\n",
      "    loader = PyPDFLoader(fn)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 92, in __init__\n",
      "    super().__init__(file_path)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/langchain/document_loaders/pdf.py\", line 56, in __init__\n",
      "    raise ValueError(\"File path %s is not a valid file or url\" % self.file_path)\u001b[0m\n",
      "\u001b[34mValueError: File path FM_7-0.pdf is not a valid file or url\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job llm-apps-blog-job-2023-08-15-11-42-54-933: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# ready to run the processing job\u001b[39;00m\n\u001b[1;32m     33\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontainer/load_data_into_opensearch.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m              \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m              \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m              \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--opensearch-cluster-domain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopensearch_domain_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--opensearch-secretid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos_creds_secretid_in_secrets_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--opensearch-index-name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopensearch_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--aws-region\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maws_region\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--embeddings-model-endpoint-name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_model_endpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--chunk-size-for-doc-split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_SIZE_FOR_DOC_SPLIT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--chunk-overlap-for-doc-split\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_OVERLAP_FOR_DOC_SPLIT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--input-data-dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/opt/ml/processing/input_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--create-index-hint-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCREATE_OS_INDEX_HINT_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--process-count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m st\n\u001b[1;32m     48\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing job completed, total time taken=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_taken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:688\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:1113\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits for the processing job to complete.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    logs (bool): Whether to show the logs produced by the job (default: True).\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m-> 1113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4925\u001b[0m, in \u001b[0;36mSession.logs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   4924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4925\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   4927\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:6813\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6809\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6810\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6811\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6812\u001b[0m     )\n\u001b[0;32m-> 6813\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6814\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6815\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6816\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6817\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job llm-apps-blog-job-2023-08-15-11-42-54-933: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "# setup the parameters for the job\n",
    "base_job_name = f\"{app_name}-job\"\n",
    "tags = [{\"Key\": \"data\", \"Value\": \"embeddings-for-llm-apps\"}]\n",
    "\n",
    "# use the custom container we just created\n",
    "image_uri = f\"{account_id}.dkr.ecr.{aws_region}.amazonaws.com/{IMAGE}:{IMAGE_TAG}\"\n",
    "\n",
    "# instance type and count determined via trial and error: how much overall processing time\n",
    "# and what compute cost works best for your use-case\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 3\n",
    "logger.info(f\"base_job_name={base_job_name}, tags={tags}, image_uri={image_uri}, instance_type={instance_type}, instance_count={instance_count}\")\n",
    "\n",
    "# setup the ScriptProcessor with the above parameters\n",
    "processor = ScriptProcessor(base_job_name=base_job_name,\n",
    "                            image_uri=image_uri,\n",
    "                            role=aws_role,\n",
    "                            instance_type=instance_type,\n",
    "                            instance_count=instance_count,\n",
    "                            command=[\"python3\"],\n",
    "                            tags=tags)\n",
    "\n",
    "# setup input from S3, note the ShardedByS3Key, this ensures that \n",
    "# each instance gets a random and equal subset of the files in S3.\n",
    "inputs = [ProcessingInput(source=f\"s3://{bucket}/{app_name}/{DOMAIN}\",\n",
    "                          destination='/opt/ml/processing/input_data',\n",
    "                          s3_data_distribution_type='ShardedByS3Key',\n",
    "                          s3_data_type='S3Prefix')]\n",
    "\n",
    "\n",
    "logger.info(f\"creating an opensearch index with name={opensearch_index}\")\n",
    "# ready to run the processing job\n",
    "st = time.time()\n",
    "processor.run(code=\"container/load_data_into_opensearch.py\",\n",
    "              inputs=inputs,\n",
    "              outputs=[],\n",
    "              arguments=[\"--opensearch-cluster-domain\", opensearch_domain_endpoint,\n",
    "                         \"--opensearch-secretid\", os_creds_secretid_in_secrets_manager,\n",
    "                         \"--opensearch-index-name\", opensearch_index,\n",
    "                         \"--aws-region\", aws_region,\n",
    "                         \"--embeddings-model-endpoint-name\", embeddings_model_endpoint_name,\n",
    "                         \"--chunk-size-for-doc-split\", str(CHUNK_SIZE_FOR_DOC_SPLIT),\n",
    "                         \"--chunk-overlap-for-doc-split\", str(CHUNK_OVERLAP_FOR_DOC_SPLIT),\n",
    "                         \"--input-data-dir\", \"/opt/ml/processing/input_data\",\n",
    "                         \"--create-index-hint-file\", CREATE_OS_INDEX_HINT_FILE,\n",
    "                         \"--process-count\", \"2\"])\n",
    "time_taken = time.time() - st\n",
    "logger.info(f\"processing job completed, total time taken={time_taken}s\")\n",
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "logger.info(preprocessing_job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087307b9-ab77-4956-9308-7856b515583e",
   "metadata": {},
   "source": [
    "## Step 4: Do a similarity search for for user input to documents (embeddings) in OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a19dc18b-42ba-4236-85db-63998effeec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:40:48,880,base,MainProcess,WARNING,POST https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com:443/%3Clangchain.vectorstores.faiss.FAISS%20object%20at%200x7f898bb9b790%3E/_search [status:404 request:0.051s]\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'index_not_found_exception', 'no such index [langchain.vectorstores.faiss.FAISS object at 0x7f898bb9b790]', langchain.vectorstores.faiss.FAISS object at 0x7f898bb9b790, index_or_alias)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-e3b204944dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                    http_auth=http_auth)\n\u001b[1;32m     12\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What's the proper tactic?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, search_type=\"script_scoring\", space_type=\"cosinesimil\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/langchain/vectorstores/opensearch_vector_search.py\u001b[0m in \u001b[0;36msimilarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid `search_type` provided as an argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_source\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         documents = [\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/client/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, body, index, params, headers)\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"from_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m         return self.transport.perform_request(\n\u001b[0m\u001b[1;32m   1552\u001b[0m             \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0m_make_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_search\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 status, headers_response, data = connection.perform_request(\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             )\n\u001b[0;32m--> 266\u001b[0;31m             self._raise_error(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/opensearchpy/connection/base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data, content_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Undecodable raw error response from server: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: NotFoundError(404, 'index_not_found_exception', 'no such index [langchain.vectorstores.faiss.FAISS object at 0x7f898bb9b790]', langchain.vectorstores.faiss.FAISS object at 0x7f898bb9b790, index_or_alias)"
     ]
    }
   ],
   "source": [
    "from container.credentials import get_credentials\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from container.sm_helper import create_sagemaker_embeddings_from_js_model\n",
    "\n",
    "creds = get_credentials(os_creds_secretid_in_secrets_manager, aws_region)\n",
    "http_auth = (creds['username'], creds['password'])\n",
    "docsearch = OpenSearchVectorSearch(index_name=opensearch_index,\n",
    "                                   embedding_function=create_sagemaker_embeddings_from_js_model(\"jumpstart-dft-hf-textembedding-gpt-j-6b\",\n",
    "                                                                                                aws_region),\n",
    "                                   opensearch_url=opensearch_domain_endpoint,\n",
    "                                   http_auth=http_auth)\n",
    "q = \"What's the proper tactic?\"\n",
    "docs = docsearch.similarity_search(q, k=3) #, search_type=\"script_scoring\", space_type=\"cosinesimil\"\n",
    "for doc in docs:\n",
    "    logger.info(\"----------\")\n",
    "    logger.info(f\"content=\\\"{doc.page_content}\\\",\\nmetadata=\\\"{doc.metadata}\\\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22cc4506-c4dc-4b79-8c59-e387f3354ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://search-opensearchservi-hsbfpnvhbwad-j3tnhubetgqlqzyncn7hyxvj7u.us-east-1.es.amazonaws.com'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opensearch_domain_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8cfcd643-ead8-414e-bc6e-254ad273d7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a43f6-ca23-484d-a3c1-c84292c83112",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "To avoid incurring future charges, delete the resources. You can do this by deleting the CloudFormation template used to create the IAM role and SageMaker notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0613c5-9567-4767-a260-e6d050349fb7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "In this notebook we were able to see how to use LLMs deployed on a SageMaker Endpoint to generate embeddings and then ingest those embeddings into OpenSearch and finally do a similarity search for user input to the documents (embeddings) stored in OpenSearch. We used langchain as an abstraction layer to talk to both the SageMaker Endpoint as well as OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dd6df6f4-e5b6-45d4-8f2a-5637a8ca2cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or element might happen to be located on the battlefield. However, the function (and hence the functional designation) of a particular force or element may change during the course of the battle. The use of precise functional designations for every force or element on the battlefield allows for a clearer understanding by \n",
      "subordinate units of the distinctive functions their co mmander expects them to perform. It also allows each \n",
      "force or element to know exactly wh at all of the others are doing at any time. This knowledge facilitates\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the 5 types of combat formations normally used by the tank platoon? Give the answer in a list\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a1f223c5-f614-4677-ade6-8cd613389cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='or element might happen to be located on the battlefield. However, the function (and hence the functional designation) of a particular force or element may change during the course of the battle. The use of precise functional designations for every force or element on the battlefield allows for a clearer understanding by \\nsubordinate units of the distinctive functions their co mmander expects them to perform. It also allows each \\nforce or element to know exactly wh at all of the others are doing at any time. This knowledge facilitates', metadata={'source': 'docs/14 OPFOR Tactics.pdf', 'page': 48, 'timestamp': 1690908480.3316243, 'embeddings_model': 'llm-apps-blog-gpt-j-6b-endpoint-152d6870'}),\n",
       " Document(page_content='forces can shift dramatically during the course of a battle, if part of the plan does not work or works better than anticipated. For example, a unit that started out being part of a fixing force might split off and become an exploitation force, if the opportunity presents itself. \\n3-23.  Each functional force has an identified commander. This is often the senior commander of the largest \\nsubordinate unit assigned to that force. For example, if two BTGs are acting as the DTG’s fixing force, the senior of the two BTG commanders is the fixing fo rce commander. Since, in this option, each force', metadata={'source': 'docs/14 OPFOR Tactics.pdf', 'page': 71, 'timestamp': 1690908480.3316445, 'embeddings_model': 'llm-apps-blog-gpt-j-6b-endpoint-152d6870'}),\n",
       " Document(page_content='Introduction \\nxiv TC 7-100.2 9 December 2011 In the OPFOR baseline presented in this TC, the aut hors often say that the State or the OPFOR “may” be \\nable to do something or “might” or “could” do something. They often use the progressive forms of verbs to say that the State “is developing” a capability or “is continually modernizing.” The State participates in the global market, which can allow it to acquire things it cannot produce domestically. Such descriptions give \\nscenario writers considerable flexibility in determining what the State or the OPFOR actually has at a given \\npoint in time or a given place on the battlefield ⎯in a particular scenario. \\nTHINKING  \\nThis TC describes how the OPFOR thinks, especially  how it thinks about fighting its regional neighbors', metadata={'source': 'docs/14 OPFOR Tactics.pdf', 'page': 15, 'timestamp': 1690908480.3315928, 'embeddings_model': 'llm-apps-blog-gpt-j-6b-endpoint-152d6870'}),\n",
       " Document(page_content='5-18.  Execution of the breaking contact battle drill varies depending on the situation and the commander’s \\nbattle plan. The breaking contact battle drill is accomplis hed by performing the follo wing subtasks. In most \\ncases, all subtasks are part of the breaking contact battle drill. However, the first three subtasks may be executed in a variety of ways. Figure 5-2 shows an example of breaking contact. \\n \\nFixManeuver\\nContact\\nEnemyAction Element\\nSupport ElementSecurity ElementOPFOR\\nC3DII\\n \\nFigure 5-2. Breaking contact (example)', metadata={'source': 'docs/14 OPFOR Tactics.pdf', 'page': 151, 'timestamp': 1690908480.3317223, 'embeddings_model': 'llm-apps-blog-gpt-j-6b-endpoint-152d6870'})]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6557626-87f1-4399-9c22-ba58614cee85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
